{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-mean Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv('C:\\Users\\Sanujit\\Downloads\\iris.csv') \n",
    "## Store the target vaue\n",
    "classes = df['Species']  \n",
    "## Drop the Id and Class values from dat\n",
    "df = df.drop(['Id','Species'],axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Convert dataframe into list and then into a numpy array\n",
    "data = df.values.tolist() \n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making train, test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Shuffle classes and data \n",
    "data,classes = shuffle(data,classes) \n",
    "## First 135 points are used for training and the rest is used for testing\n",
    "train_data = data[:135]  \n",
    "test_data = data[135:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-3e8bc8880a0f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mcluster_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mcluster_3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mpoint\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[1;31m## Find the eucledian distance between all points the centroid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         dis_point_c1 = ((c1[0]-point[0])**2 + (c1[1]-point[1])**2 + \n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_data' is not defined"
     ]
    }
   ],
   "source": [
    "## Randomly place the centroids of the three clusters \n",
    "c1 = [float(np.random.randint(4,8)),float(np.random.randint(1,5)),\n",
    "      float(np.random.randint(1,7)),float(np.random.randint(0,3))]\n",
    "c2 = [float(np.random.randint(4,8)),float(np.random.randint(1,5)),\n",
    "      float(np.random.randint(1,7)),float(np.random.randint(0,3))]\n",
    "c3 = [float(np.random.randint(4,8)),float(np.random.randint(1,5)),\n",
    "      float(np.random.randint(1,7)),float(np.random.randint(0,3))]\n",
    "## Intialize the number of iterations you want to run \n",
    "epochs = 1\n",
    "while(epochs <= 100):\n",
    "    cluster_1 = []\n",
    "    cluster_2 = []\n",
    "    cluster_3 = []\n",
    "    for point in train_data:\n",
    "        ## Find the eucledian distance between all points the centroid\n",
    "        dis_point_c1 = ((c1[0]-point[0])**2 + (c1[1]-point[1])**2 + \n",
    "                        (c1[2]-point[2])**2 + (c1[3]-point[3])**2)**0.5\n",
    "        dis_point_c2 = ((c2[0]-point[0])**2 + (c2[1]-point[1])**2 + \n",
    "                        (c2[2]-point[2])**2 + (c2[3]-point[3])**2)**0.5\n",
    "        dis_point_c3 = ((c3[0]-point[0])**2 + (c3[1]-point[1])**2 + \n",
    "                        (c3[2]-point[2])**2 + (c3[3]-point[3])**2)**0.5\n",
    "        distances = [dis_point_c1,dis_point_c2,dis_point_c3]\n",
    "        ## Find the closest centroid to the point and assign the point to that cluster\n",
    "        pos = distances.index(min(distances))\n",
    "        if(pos == 0):\n",
    "            cluster_1.append(point)\n",
    "        elif(pos == 1):\n",
    "            cluster_2.append(point)\n",
    "        else:\n",
    "            cluster_3.append(point)\n",
    "    ## Store the centroid values to calculate new centroid values \n",
    "    prev_c1 = c1\n",
    "    prev_c2 = c2\n",
    "    prev_c3 = c3\n",
    "    cluster_1 = np.array(cluster_1)\n",
    "    cluster_2 = np.array(cluster_2)\n",
    "    cluster_3 = np.array(cluster_3)\n",
    "    ## Find mean of all points within a cluster and make it as the centroid \n",
    "    if(len(cluster_1) != 0):\n",
    "        c1 = [sum(cluster_1[:,0])/float(len(cluster_1)),\n",
    "              sum(cluster_1[:,1])/float(len(cluster_1)),\n",
    "              sum(cluster_1[:,2])/float(len(cluster_1)),\n",
    "              sum(cluster_1[:,3])/float(len(cluster_1))]\n",
    "    if(len(cluster_2) != 0):\n",
    "        c2 = [sum(cluster_2[:,0])/float(len(cluster_2)),\n",
    "              sum(cluster_2[:,1])/float(len(cluster_2)),\n",
    "              sum(cluster_2[:,2])/float(len(cluster_2)),\n",
    "              sum(cluster_2[:,3])/float(len(cluster_2))]\n",
    "    if(len(cluster_3) != 0):\n",
    "        c3 = [sum(cluster_3[:,0])/float(len(cluster_3)),\n",
    "              sum(cluster_3[:,1])/float(len(cluster_3)),\n",
    "              sum(cluster_3[:,2])/float(len(cluster_3)),\n",
    "              sum(cluster_3[:,3])/float(len(cluster_3))]\n",
    "    ## If centroid values hasn't changed, algorithm has convereged \n",
    "    if(prev_c1 == c1 and prev_c2 == c2 and prev_c3 == c3):\n",
    "        print(\"Converged\")\n",
    "        break\n",
    "    print(epochs)\n",
    "    epochs += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We implement the code shown above and we can find that our algorithm converges after some iterations. We can now input a test data point and find the centroid it is closest to and assign that point to the respective cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = []\n",
    "for point in test_data:\n",
    "    ## Find distance between test data point and centroids\n",
    "    dis_point_c1 = ((c1[0]-point[0])**2 + (c1[1]-point[1])**2 + \n",
    "                    (c1[2]-point[2])**2 + (c1[3]-point[3])**2)**0.5\n",
    "    dis_point_c2 = ((c2[0]-point[0])**2 + (c2[1]-point[1])**2 + \n",
    "                    (c2[2]-point[2])**2 + (c2[3]-point[3])**2)**0.5\n",
    "    dis_point_c3 = ((c3[0]-point[0])**2 + (c3[1]-point[1])**2 + \n",
    "                    (c3[2]-point[2])**2 + (c3[3]-point[3])**2)**0.5\n",
    "    ## Find the cluster to which the point is closest to and append \n",
    "    ## it to pred\n",
    "    distances = [dis_point_c1,dis_point_c2,dis_point_c3]\n",
    "    pos = distances.index(min(distances))\n",
    "    pred.append(pos)\n",
    "    ## Print the predictions \n",
    "    print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the Scikit-learn library\n",
    "K-means is an introductory algorithm to clustering techniques and it is the simplest of them. When done using library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-e4c5322fd6b7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcluster\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_clusters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_data' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans \n",
    "clf = KMeans(n_clusters = 3)\n",
    "clf.fit(train_data)\n",
    "pred = clf.predict(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Good Job!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
